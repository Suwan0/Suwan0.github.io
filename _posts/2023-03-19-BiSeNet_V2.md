---
title: "BiSeNetV2 Model구조 정리 및 실행"
date: 2023-03-19 21:24:00 -0400
categories: jekyll update
---

이번 post에서는 BiSeNetV2의 구조에 대해 간단하게 정리하고 실행하는 방법을 알아보자.

# BiSeNet V2
- Model 구조
    - Pytorch를 통한 구현
- 실행
    - CityScape Data
    - Custom Data

## Model 구조

![Screenshot from 2023-03-19 20-29-12](https://user-images.githubusercontent.com/122383307/226174603-6aa66a35-17c5-4df5-a477-5ca89790bccb.png)
BiseNetV2 구조

- 위의 이미지는 BiSeNetV2의 model 이미지이다.
- 일반적인 딥러닝 모델의 구조들과 다름을 확인할 수 있다.
    - 일반적인 모델은 spatial detail과 categorical semantics를 따로 다루지 않지만 BiSeNet은 따로 구현한다.(Two-pathway architecture)
    - 위의 two pathway를 각각 Detail Branch(spatial detail)와 Semantic Branch(categorical semantics)라고 한다.
        - 위의 그림에서 보면 하늘색 Branch와 초록색 Branch로 나타나 있는 것을 볼 수 있다.
    - 그리고 Semantic Branch에서 각 단계마다 Seg Head를 통해서 Loss를 계산하는 Booster 층이 있는 것을 확인할 수 있다.
- 크게 나눠보자면 그림에 나와있는 대로 Backbone, Aggregation Layer, Booster, Seg Head와 그 안을 구성하는 구조들로 나타낼 수 있다.
    - 모델의 구조를 구분해보자면 Detail Branch, Semantic Branch, Aggregation Layer, Stem Block, Context Embedding Block, Gather-and-Expansion Layer, Bilateral Guided Aggregation Layer, Segment Head로 이루어져 있음을 확인할 수 있다.
    - Model에 대한 자세한 내용은 논문 리뷰에서 확인할 수 있다.

## 각각의 구조를 Pytorch를 이용해서 구현

- Detail Branch, Semantic Branch, Aggregation Layer, Stem Block, Context Embedding Block, Gather-and-Expansion Layer, Bilateral Guided Aggregation Layer, Segment Head를 각각 구현

![Untitled 1](https://user-images.githubusercontent.com/122383307/226356312-907796a5-ec97-4cb7-8c4f-b4d1c06c522e.png)

- Detail Branch와 Semantic Branch를 보면 내부 구조가 Conv2d, Stem 그리고 GE로 이루어져 있는 것을 확인할 수 있다.
    - 먼저 위의 표에 맞게 Detail Branch와 Segment Branch를 작성해보자.

```python
class DetailBranch(nn.Module):

    def __init__(self):
        super(DetailBranch, self).__init__()
        self.S1 = nn.Sequential(
            ConvBNReLU(3, 64, 3, stride=2),
            ConvBNReLU(64, 64, 3, stride=1),
        )
        self.S2 = nn.Sequential(
            ConvBNReLU(64, 64, 3, stride=2),
            ConvBNReLU(64, 64, 3, stride=1),
            ConvBNReLU(64, 64, 3, stride=1),
        )
        self.S3 = nn.Sequential(
            ConvBNReLU(64, 128, 3, stride=2),
            ConvBNReLU(128, 128, 3, stride=1),
            ConvBNReLU(128, 128, 3, stride=1),
        )

	def forward(self, x):
        feat = self.S1(x)
        feat = self.S2(feat)
        feat = self.S3(feat)
        return feat

class SegmentBranch(nn.Module):

    def __init__(self):
        super(SegmentBranch, self).__init__()
        self.S1S2 = StemBlock()
        self.S3 = nn.Sequential(
            GELayerS2(16, 32),
            GELayerS1(32, 32),
        )
        self.S4 = nn.Sequential(
            GELayerS2(32, 64),
            GELayerS1(64, 64),
        )
        self.S5_4 = nn.Sequential(
            GELayerS2(64, 128),
            GELayerS1(128, 128),
            GELayerS1(128, 128),
            GELayerS1(128, 128),
        )
        self.S5_5 = CEBlock()
		def forward(self, x):
		        feat2 = self.S1S2(x)
		        feat3 = self.S3(feat2)
		        feat4 = self.S4(feat3)
		        feat5_4 = self.S5_4(feat4)
		        feat5_5 = self.S5_5(feat5_4)
		        return feat2, feat3, feat4, feat5_4, feat5_5
```

![Untitled 2](https://user-images.githubusercontent.com/122383307/226356425-7bf0c5ce-8553-4ceb-b150-a745d22f5e07.png)

- Semantic Branch의 first stage에 Stem Block을 적용하고 마지막 stage에 Context Embedding Block을 적용한다.
    - 코드로 구현해보면 다음과 같이 나타낼 수 있다

```python
class StemBlock(nn.Module):

    def __init__(self):
        super(StemBlock, self).__init__()
        self.conv = ConvBNReLU(3, 16, 3, stride=2)
        self.left = nn.Sequential(
            ConvBNReLU(16, 8, 1, stride=1, padding=0),
            ConvBNReLU(8, 16, 3, stride=2),
        )
        self.right = nn.MaxPool2d(
            kernel_size=3, stride=2, padding=1, ceil_mode=False)
        self.fuse = ConvBNReLU(32, 16, 3, stride=1)

    def forward(self, x):
        feat = self.conv(x)
        feat_left = self.left(feat)
        feat_right = self.right(feat)
        feat = torch.cat([feat_left, feat_right], dim=1)
        feat = self.fuse(feat)
        return feat

class CEBlock(nn.Module):

    def __init__(self):
        super(CEBlock, self).__init__()
        self.bn = nn.BatchNorm2d(128)
        self.conv_gap = ConvBNReLU(128, 128, 1, stride=1, padding=0)
        self.conv_last = ConvBNReLU(128, 128, 3, stride=1)

    def forward(self, x):
        feat = torch.mean(x, dim=(2, 3), keepdim=True)
        feat = self.bn(feat)
        feat = self.conv_gap(feat)
        feat = feat + x
        feat = self.conv_last(feat)
        return feat
```

![Untitled 3](https://user-images.githubusercontent.com/122383307/226356492-c22ffe9a-7055-4fcd-b938-11a4bcea4144.png)

- GE layer를 보면 (b)는 stride=1인 layer이고 (c)는 stride=2인 layer이다.
    - 이를 코드로 구현해보자

```python
#Stride=1인 GE layer
class GELayerS1(nn.Module):

    def __init__(self, in_chan, out_chan, exp_ratio=6):
        super(GELayerS1, self).__init__()
        mid_chan = in_chan * exp_ratio
        self.conv1 = ConvBNReLU(in_chan, in_chan, 3, stride=1)
        self.dwconv = nn.Sequential(
            nn.Conv2d(
                in_chan, mid_chan, kernel_size=3, stride=1,
                padding=1, groups=in_chan, bias=False),
            nn.BatchNorm2d(mid_chan),
            nn.ReLU(inplace=True),
        )
        self.conv2 = nn.Sequential(
            nn.Conv2d(
                mid_chan, out_chan, kernel_size=1, stride=1,
                padding=0, bias=False),
            nn.BatchNorm2d(out_chan),
        )
        self.conv2[1].last_bn = True
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        feat = self.conv1(x)
        feat = self.dwconv(feat)
        feat = self.conv2(feat)
        feat = feat + x
        feat = self.relu(feat)
        return feat

#Stride=2인 GE layer
class GELayerS2(nn.Module):

    def __init__(self, in_chan, out_chan, exp_ratio=6):
        super(GELayerS2, self).__init__()
        mid_chan = in_chan * exp_ratio
        self.conv1 = ConvBNReLU(in_chan, in_chan, 3, stride=1)
        self.dwconv1 = nn.Sequential(
            nn.Conv2d(
                in_chan, mid_chan, kernel_size=3, stride=2,
                padding=1, groups=in_chan, bias=False),
            nn.BatchNorm2d(mid_chan),
        )
        self.dwconv2 = nn.Sequential(
            nn.Conv2d(
                mid_chan, mid_chan, kernel_size=3, stride=1,
                padding=1, groups=mid_chan, bias=False),
            nn.BatchNorm2d(mid_chan),
            nn.ReLU(inplace=True),
        )
        self.conv2 = nn.Sequential(
            nn.Conv2d(
                mid_chan, out_chan, kernel_size=1, stride=1,
                padding=0, bias=False),
            nn.BatchNorm2d(out_chan),
        )
        self.conv2[1].last_bn = True
        self.shortcut = nn.Sequential(
                nn.Conv2d(
                    in_chan, in_chan, kernel_size=3, stride=2,
                    padding=1, groups=in_chan, bias=False),
                nn.BatchNorm2d(in_chan),
                nn.Conv2d(
                    in_chan, out_chan, kernel_size=1, stride=1,
                    padding=0, bias=False),
                nn.BatchNorm2d(out_chan),
        )
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        feat = self.conv1(x)
        feat = self.dwconv1(feat)
        feat = self.dwconv2(feat)
        feat = self.conv2(feat)
        shortcut = self.shortcut(x)
        feat = feat + shortcut
        feat = self.relu(feat)
        return feat
```

![Untitled 4](https://user-images.githubusercontent.com/122383307/226356559-bcff4535-b7e9-4ec8-ad4e-a13b224a584c.png)

- BGA layer 구현

```python
class BGALayer(nn.Module):

    def __init__(self):
        super(BGALayer, self).__init__()
        self.left1 = nn.Sequential(
            nn.Conv2d(
                128, 128, kernel_size=3, stride=1,
                padding=1, groups=128, bias=False),
            nn.BatchNorm2d(128),
            nn.Conv2d(
                128, 128, kernel_size=1, stride=1,
                padding=0, bias=False),
        )
        self.left2 = nn.Sequential(
            nn.Conv2d(
                128, 128, kernel_size=3, stride=2,
                padding=1, bias=False),
            nn.BatchNorm2d(128),
            nn.AvgPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=False)
        )
        self.right1 = nn.Sequential(
            nn.Conv2d(
                128, 128, kernel_size=3, stride=1,
                padding=1, bias=False),
            nn.BatchNorm2d(128),
        )
        self.right2 = nn.Sequential(
            nn.Conv2d(
                128, 128, kernel_size=3, stride=1,
                padding=1, groups=128, bias=False),
            nn.BatchNorm2d(128),
            nn.Conv2d(
                128, 128, kernel_size=1, stride=1,
                padding=0, bias=False),
        )
        self.conv = nn.Sequential(
            nn.Conv2d(
                128, 128, kernel_size=3, stride=1,
                padding=1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True), 
        )

    def forward(self, x_d, x_s):
        dsize = x_d.size()[2:]
        left1 = self.left1(x_d)
        left2 = self.left2(x_d)
        right1 = self.right1(x_s)
        right2 = self.right2(x_s)
        right1 = F.interpolate(
            right1, size=dsize, mode='bilinear', align_corners=True)
        left = left1 * torch.sigmoid(right1)
        right = left2 * torch.sigmoid(right2)
        right = F.interpolate(
            right, size=dsize, mode='bilinear', align_corners=True)
        out = self.conv(left + right)
        return out
```

![Untitled 5](https://user-images.githubusercontent.com/122383307/226356623-e1dc7c50-7429-44cd-bdfb-42239ea72264.png)

- Segment Head의 구현

```python
class SegmentHead(nn.Module):

    def __init__(self, in_chan, mid_chan, n_classes):
        super(SegmentHead, self).__init__()
        self.conv = ConvBNReLU(in_chan, mid_chan, 3, stride=1)
        self.drop = nn.Dropout(0.1)
        self.conv_out = nn.Conv2d(
                mid_chan, n_classes, kernel_size=1, stride=1,
                padding=0, bias=True)

    def forward(self, x, size=None):
        feat = self.conv(x)
        feat = self.drop(feat)
        feat = self.conv_out(feat)
        if not size is None:
            feat = F.interpolate(feat, size=size,
                mode='bilinear', align_corners=True)
        return feat
```

전체 모델 구현

```python
class BiSeNetV2(nn.Module):

    def __init__(self, n_classes):
        super(BiSeNetV2, self).__init__()
        self.detail = DetailBranch()
        self.segment = SegmentBranch()
        self.bga = BGALayer()

        ## TODO: what is the number of mid chan ?
        self.head = SegmentHead(128, 1024, n_classes)
        self.aux2 = SegmentHead(16, 128, n_classes)
        self.aux3 = SegmentHead(32, 128, n_classes)
        self.aux4 = SegmentHead(64, 128, n_classes)
        self.aux5_4 = SegmentHead(128, 128, n_classes)

        self.init_weights()

    def forward(self, x):
        size = x.size()[2:]
        feat_d = self.detail(x)
        feat2, feat3, feat4, feat5_4, feat_s = self.segment(x)
        feat_head = self.bga(feat_d, feat_s)

        logits = self.head(feat_head, size)
        logits_aux2 = self.aux2(feat2, size)
        logits_aux3 = self.aux3(feat3, size)
        logits_aux4 = self.aux4(feat4, size)
        logits_aux5_4 = self.aux5_4(feat5_4, size)
        return logits, logits_aux2, logits_aux3, logits_aux4, logits_aux5_4
```

## Custom Data를 이용하여 구현

- Custom Dataset의 특징 파악
    - Image size 크기(1024*512의 크기로 맞춰서 진행)
    - Label data의 형태 파악(class의 수, 형태)
        - 6개의 class 그리고 0-5의 값으로 나타낸 label image
- Custom Dataset 정제하기
    - Image size
    - Augmentation
    - Label image를 one_hot_label 하기
        
        ![Image_Segmentation](https://user-images.githubusercontent.com/122383307/226174608-e6164d0e-d5fe-440c-9818-e2665e39d0a5.png)
        

```python
class DatasetCustom(Dataset):
    def __init__(self, img_dir, mask_dir, transform=None):
        super(DatasetCustom, self).__init__()
        self.img_dir = img_dir
        self.mask_dir = mask_dir
        self.images = os.listdir(img_dir)
        self.transform = transform

    def __len__(self):
        return len(self.images)

    def __getitem__(self, index):
        img_path = os.path.join(self.img_dir, self.images[index])
        mask_path = os.path.join(self.mask_dir, self.images[index])

        img = cv2.imread(img_path)
        img_pil = Image.fromarray(img)

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

        if self.transform:
            img = self.transform(img_pil)

        return img.to(device), torch.tensor(mask).to(device)

transform = transforms.Compose([
    transforms.ToTensor(),  
])

train_transforms = transforms.Compose([
    #transforms.RandomHorizontalFlip(p=0.5),   
    #transforms.RandomRotation(degrees=10),    
    #transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),
    transforms.ToTensor(),
    #transforms.RandomCrop(1024,512),
    #transforms.Resize(cropsize),  
    #transforms.Normalize(mean=[0.43935746, 0.4471958, 0.42968285], std=[0.29864237, 0.29265264, 0.29834712])  
])

# One hot label작업
import torch
from typing import Optional

# label을 one hot label로 만들기 위한 작업 

def label_to_one_hot_label(
    labels: torch.Tensor,
    num_classes: int,
    device: Optional[torch.device] = None,
    dtype: Optional[torch.dtype] = None,
    eps: float = 1e-6,
) -> torch.Tensor:

    labels = labels.to(device)
    shape = labels.shape
    one_hot = torch.zeros((shape[0], num_classes) + shape[1:], device=device, dtype=dtype)
    
    ret = one_hot.scatter_(1, labels.unsqueeze(1).to(device), 1.0) + eps    
    return ret
```

- Train
    - SGD optimizer 사용
    - DiceLoss 사용

```python
# Dice Loss Function
class DiceLoss(nn.Module):
    def __init__(self):
        super(DiceLoss, self).__init__()

    def forward(self, inputs, targets, smooth=1):
        
        inputs = torch.sigmoid(inputs) 
        
        inputs = inputs.view(-1)
        targets = targets.view(-1)
        
        intersection = (inputs * targets).sum()                            
        dice = (2.*intersection + smooth) / (inputs.sum() + targets.sum() + smooth)  
        
        return 1 - dice

# Training 하기
import matplotlib.pyplot as plt

optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)

num_classes = 6

# Dice Loss 사용할 때
criterion = DiceLoss()

train_acc = []
train_loss = []

batch_size = 6

for epoch in range(20):
    epoch_train_acc = 0.0
    epoch_train_loss = 0.0
    for i, data in enumerate(training_loader):
        optimizer.zero_grad()

        inputs, labels = data 
       
        inputs = inputs.view(-1, 3, 512, 1024).float()

        labels = labels.long()
        labels = labels.to(device)
        labels = label_to_one_hot_label(labels, num_classes, device=device)

        labels = labels.view(-1, num_classes, 512*1024).long()

        label = torch.argmax(labels, dim=1)

        outputs1, outputs2, outputs3, outputs4, outputs5 = model(inputs)

        outputs1 = outputs1.view(-1, num_classes, 512 * 1024) 
        outputs2 = outputs2.view(-1, num_classes, 512 * 1024)
        outputs3 = outputs3.view(-1, num_classes, 512 * 1024)
        outputs4 = outputs4.view(-1, num_classes, 512 * 1024)
        outputs5 = outputs5.view(-1, num_classes, 512 * 1024)

        loss1 = criterion(outputs1, labels)
        loss2 = criterion(outputs2, labels)
        loss3 = criterion(outputs3, labels)
        loss4 = criterion(outputs4, labels)
        loss5 = criterion(outputs5, labels)
        loss = loss1 + loss2 + loss3 + loss4 + loss5

        loss.backward()
        optimizer.step()

        preds = torch.argmax(outputs1, dim=1)
        correct = (preds == label).sum().item()
        acc = correct / (batch_size * 512 * 1024)
        epoch_train_acc += acc
        epoch_train_loss += loss.item()

    epoch_train_acc /= len(training_loader)
    epoch_train_loss /= len(training_loader)

    train_acc.append(epoch_train_acc)
    train_loss.append(epoch_train_loss)

        
    print("Epoch [{}/20], Loss: {:.3f}".format(epoch+1, loss.item()))

plt.figure(figsize=(10, 5))
plt.subplot(121)
plt.plot(train_acc, label='Train Acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(122)
plt.plot(train_loss, label='Train Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.show()
```

- Test

```python
import matplotlib.pyplot as plt

n_classes = 6
net = BiSeNetV2(6)
res_path = '/content/drive/MyDrive/'
save_pth = osp.join(res_path,'model_final.pth')
net.load_state_dict(torch.load(save_pth), strict=False) 
net.cuda()
net.eval()

vl = validation_loader

with torch.no_grad():

    hist = torch.zeros(n_classes, n_classes).cuda().detach()

    for i, data in enumerate(validation_loader):
        img, label = data
        label = label.cuda()
        size = label.size()[-2:] 
        labels = label
        img = img.cuda()
        img = img.float()
        logits = net(img)[0]

        probs = torch.softmax(logits, dim=1)
        preds = torch.argmax(probs, dim=1)

        label = label.view(-1)

        preds = preds.view(-1)

        hist += torch.bincount(
            label * n_classes + preds,
            minlength = n_classes ** 2
            ).view(n_classes, n_classes)

        plt.figure()
        plt.subplot(131)
        plt.imshow(img[0].cpu().permute(1, 2, 0))
        plt.title('Input image')
        plt.subplot(132)
        plt.imshow(labels.cpu().view(size).numpy(), cmap='gray')
        plt.title('Ground truth label')
        plt.subplot(133)
        plt.imshow(preds.cpu().view(size).numpy(), cmap='gray')
        plt.title('Predicted label')
        plt.show()

    ious = hist.diag() / (hist.sum(dim=0) + hist.sum(dim=1) - hist.diag() + 1e-6)
    print(ious)
    miou = ious.mean()

    print(miou)
```

